
## Foundations to Probability

1. [Introduction to Probability Spaces](published_notes/fundamental/intro_prob_spaces/): Introduction to representing something in a probability triplet.

2. [Introduction to Independence and Conditional Probability](published_notes/fundamental/intro_cond_prob/index.md): An introduction to intuitively understand conditional probabilities, which are instrumental in the understanding of Bayes' Theorem.

3. [Introduction to Random Variables](published_notes/fundamental/intro_rand_var/): (*Under Construction*) Understanding random variables and expectation values.

4. [Introcution to Bayesian Probability](preliminaries/intro_bayesian_prob/): (*Under Construction*) Introduction to Bayesian and Frequentist Statistics.

5. [Introcution to Entropy and Information](published_notes/fundamental/intro_entropy/): (*Under Construction*) Introduction to the concepts of entropy and information that began with Shannon's Information Theory.



## Concepts to Probability

1. [Entropy, Cross-Entropy, and KL-Divergence](published_notes/concepts_to_prob/kl_divergence/): (*Under Construction*) Expanding the concepts of information and entropy toward future mathematical applications.

2. [Bayesian networks](representation/directed/): Definitions. Representations via directed graphs. Independencies in directed models.

3. [Markov random fields](representation/undirected/): Undirected vs directed models. Independencies in undirected models. Conditional random fields.


## Applicatons to Probability: Machine Learning Pt1

1. [Variational Autoencoder](published_notes/applications_pt_1/vae): (*Under Construction*) The Variational Autoencoder is a powerful generative model with deep roots in all the previous concepts of probability we have gone over.

